<!DOCTYPE html>
<html lang="en">
<head>
        <title>A notch above a monkey</title>
        <meta charset="utf-8" />
        <link rel="shortcut icon" href="theme/img/markos.ico" />

        <link href="http://fast.fonts.com/cssapi/aee9b60b-8e94-47f8-b586-3ecbfab51d1c.css" rel="stylesheet" type="text/css" />
        <link rel="stylesheet" type="text/css" href="theme/css/home.min.css" media="screen" title="Light theme" />
        <link rel="alternate stylesheet" type="text/css" href="theme/css/home_dark.min.css" media="screen" title="Dark theme" />

        <link href="/articles/feeds/atom.xml" type="application/atom+xml" rel="alternate" title="A notch above a monkey Full Atom Feed" />
        <link href="/articles/feeds/rss.xml" type="application/rss+xml" rel="alternate" title="A notch above a monkey Full RSS Feed" />
</head>

<body>


<section class="envelope posts">
    <header>
        <h1><a href="./">A notch above a monkey <strong></strong></a></h1>
    </header><!-- /#banner -->

    <nav class="colophon">
        <h1>By Marko Samastur</h1>
        <ul>
            <li><a href="/">About me</a></li>
            <li><a href="/articles/feeds/atom.xml">Subscribe</a></li>
        </ul>
    </nav>

        <article class="hentry">
            <h1 class="entry-title storytitle"><a href="./google-ignore.html" rel="bookmark" title="Permalink to Google ignore">Google ignore</a></h1>

            <div class="entry-content post-text">
                <div>
 <p>
  A few days ago I came to
  <a href="javascript-enabled-spiders.html">
   recognize
  </a>
  that email hiding technique I use won’t work anymore. However I still think it would be a great idea if I could remove a part of a page from search index, even if it won’t help me hide from spammers in the long run.
 </p>
 <p>
  What I’d really like is to specify which parts of a page are not its content and can be safely ignored by search engines. Ignoring it would also mean absence of those parts from search indexes. Spiders could still follow links inside those parts, because I can still use
  <em>
   robots.txt
  </em>
  file if I really want to block their traversal. In effect, I’d like a more fine-grained approach to blocking, which doesn’t force the layout of my pages to even slightly favor spiders over people.
 </p>
 <p>
  The way I imagine it would work is by simply applying a class name to the parts of the page I’d want shielded. I don’t care much (yet) if such class name would need to be specified in robots file or if it would be some name achieved by a web consensus. As far as I can see both approaches would work equally well.
 </p>
 <p>
  The benefit of this would also be better search results. Every now and then I follow a search hit that fit my query because of a combination of site content and its navigation. Judging by my logs I’m not the only deceived soul. So, wouldn’t it be nice to be able to tell which parts are content and which aren’t?
 </p>
</div>
            </div><!-- /.entry-content -->

            <footer class="post-metadata">
                <ul>
                    <li>Published on <time datetime="2006-04-10T13:59:00+02:00">Mon 10 April 2006</time> </li>
                    <li><a href="./google-ignore.html">Add your comment</a></li>
                </ul>
            </footer>
        </article>
        <article class="hentry">
            <h1 class="entry-title storytitle"><a href="./simple-list-extensions.html" rel="bookmark" title="Permalink to Simple List Extensions">Simple List Extensions</a></h1>

            <div class="entry-content post-text">
                <div>
 <p>
  I’m not sure how I missed the original announcement of Simple List Extensions (SLE) for feeds, but better late than never.
 </p>
 <p>
  SLE is a very simple specification to extend feeds syntax to better support some common scenarios that weren’t covered with original specifications of RSS and Atom. Previously there was no way to tell feed readers/aggregators to display feed items in fixed order (e.g. feed with most popular stories of the day) or delete items not present in feed anymore (e.g. auction site feed with items matching a query).
 </p>
 <p>
  SLE also adds support for grouping and filtering of feed items, which might not be very useful with you average 10-item feed, but will be, if feeds will indeed become a general mechanism for transporting data and not only a tool to highlight most recent bunch of updates. In any case, you can read a very short
  <a href="http://msdn.microsoft.com/xml/rss/sle/">
   specification
  </a>
  or visit
  <a href="http://blogs.msdn.com/ie/archive/2006/03/30/565222.aspx">
   latest announcement
  </a>
  which includes more explanatory links to why and how they can and already are used.
 </p>
 <p>
  By the way, I’m not sure if any reader apart from beta of IE7 already supports SLE, but I expect that most of them will soon. There’s little reason not to.
 </p>
</div>
            </div><!-- /.entry-content -->

            <footer class="post-metadata">
                <ul>
                    <li>Published on <time datetime="2006-04-09T14:05:00+02:00">Sun 09 April 2006</time> </li>
                    <li><a href="./simple-list-extensions.html">Add your comment</a></li>
                </ul>
            </footer>
        </article>
        <article class="hentry">
            <h1 class="entry-title storytitle"><a href="./javascript-enabled-spiders.html" rel="bookmark" title="Permalink to Javascript enabled spiders">Javascript enabled spiders</a></h1>

            <div class="entry-content post-text">
                <div>
 <p>
  One of more popular javascript scripts I’ve written is a simple function that hides an email address from spiders by constructing a mailto link on page load. So far it has worked quite well.
 </p>
 <p>
  Lately I started to have my doubts about this approach though. There was
  <a href="http://www.google.com/search?hl=en&amp;q=mozilla+google+spider&amp;btnG=Google+Search">
   a series of articles
  </a>
  a while ago about Google’s new Mozilla-based spider that I didn’t take too seriously at the time. However, even if not true then, it’s still only a matter of time before a spider like this will show up. The new found popularity of AJAX/Javascript simply guarantees that, since search engines can’t and won’t give up indexing content hidden behind fancy scripts.
 </p>
 <p>
  Which means that my script will stop working in not so distant future as will all email obfuscating scripts out there. If it can be seen by a human, then it will be seen by a spider. So is there a way to publish my email address without it becoming public through search engines indexes, which is where most spammers seem to get our emails?
 </p>
 <p>
  I could write a robots.txt file, which would exempt my contact page from being indexed at all. But this is a rather crude approach, since it means nothing on that page will get indexed. I could move email information to a separate page to let other contact data get indexed, but this is hardly any nicer.
 </p>
 <p>
  What I’d really want is to be able to tell to search engines that only a part of my document is off limits. I don’t think there’s currently a way to do this, but if anyone has an idea how to do it, I’d really like to hear it.
 </p>
 <p>
  <strong>
   Update:
  </strong>
  I think all efforts, including mine, to prevent spammers from collecting published addresses are ultimately doomed. The basic premise of all such approaches is to cloak an address in a way that spider can’t see it or can’t recognize it if it does. By basing spider on something like Mozilla, there won’t be any difference between what spider sees and what user does. There’s a similar problem with recognition. As spiders gets smarter, as they invariably do, you’ll be getting ever growing overlap between smartest spiders and stupidest users until it’s big enough to be unacceptable.
 </p>
 <p>
  So we’ll either put up contact forms or I hope move to defending our inboxes with smart spam filters (those who haven’t yet).
 </p>
</div>
            </div><!-- /.entry-content -->

            <footer class="post-metadata">
                <ul>
                    <li>Published on <time datetime="2006-04-07T17:23:00+02:00">Fri 07 April 2006</time> </li>
                    <li><a href="./javascript-enabled-spiders.html">Add your comment</a></li>
                </ul>
            </footer>
        </article>

<p class="paginator">
        <a href="./index64.html">&laquo;</a>
    Page 65 / 111
        <a href="./index66.html">&raquo;</a>
</p>
</section><!-- /#content -->

    <footer>
        <ul>
            <li>&copy; 2005-2015 Marko Samastur</li>
            <li><a href="/articles/feeds/rss.xml" rel="alternate" title="A notch above a monkey Full RSS Feed">Entries feed</a></li>
        </ul>
        <a href="/"><img src="/img/markos_light_small_bg.png" alt="logo" class="mini-logo" /></a>
    </footer>
</body>
</html>