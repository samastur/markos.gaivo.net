<!DOCTYPE html>
<html lang="en">
<head>
	<title>A notch above a monkey &raquo; General development</title>
	<meta charset="utf-8" />
	
	<meta name="viewport" content="width=device-width, initial-scale=1.0" /> 

	<link rel="shortcut icon" href="/img/markos.ico" />
	
	<meta name="generator" content="WordPress 3.0.5" /> <!-- leave this for stats please -->

	<link href="http://fast.fonts.com/cssapi/aee9b60b-8e94-47f8-b586-3ecbfab51d1c.css" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" type="text/css" href="css/home.css" media="screen" title="Light theme" />
	<link rel="alternate stylesheet" type="text/css" href="css/home_dark.css" media="screen" title="Dark theme" />
	<link rel="stylesheet" href="css/ipad.css" media="only screen and (min-device-width : 768px) and (max-device-width : 1024px)">
	<link rel="stylesheet" type="text/css" href="css/smallscreen.css" media="only screen and (max-width: 700px)" />

	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://markos.gaivo.net/blog/?feed=rss2" />
	<link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="http://markos.gaivo.net/blog/?feed=atom" />
	<link rel='canonical' href='http://markos.gaivo.net/blog/?p=664' />

	<link rel="pingback" href="http://markos.gaivo.net/blog/xmlrpc.php" />

	<link rel="alternate" type="application/rss+xml" title="A notch above a monkey &raquo; General development Category Feed" href="http://markos.gaivo.net/blog/?feed=rss2&amp;cat=5" />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://markos.gaivo.net/blog/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://markos.gaivo.net/blog/wp-includes/wlwmanifest.xml" /> 
<link rel='index' title='A notch above a monkey' href='http://markos.gaivo.net/blog' />
<meta name="generator" content="WordPress 3.0.5" />

	<!--[if lt IE 9]>
	<script src="/js/html5.js"></script>
	<![endif]-->
</head>
<body>
	<section class="envelope posts">
		<header>
			<h1><a href="http://markos.gaivo.net/blog/">A notch above a monkey</a></h1>
		</header>
		<nav class="colophon">
			<h1>By Marko Samastur</h1>
			<ul>
				<li><a href="/">About me</a></li>
				<li><a href="http://markos.gaivo.net/blog/?feed=atom">Subscribe</a></li>
			</ul>
		</nav>

	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=211" rel="bookmark">Speeding up Levenshtein</a></h1>

			<div class="post-text">
				<p><a href="http://markos.gaivo.net/blog/?p=210#postcomment">Simon</a> proposes using a dictionary to match mistyped URLs with real ones. I&#8217;d probably like the idea better if I actually understood it. Still using <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" title="description of the algorithm">Levenshtein</a> can be a bit easier than using a spell checker responsively.</p>
<p>Easier, but slow. I used existing <a href="http://hetland.org/python/distance.py" title="python implementation">implementation</a> by Magnus Lie Hetland and made a test with 245 blog titles using a simple <a href="http://markos.gaivo.net/examples/distance/test_distance" title="Link to test script">script</a>. 100 iterations on aging powerbook produced:</p>
<p style="text-indent:20pt;">1.766s, 29.152s, 9.399s (min, max, avg)</p>
<p>Average time to calculate distance between randomly chosen title and rest of them is 9.4 seconds, which is far too much to be useful. And there&#8217;s not even 250 of them.</p>
<p>There are two obvious ways to speed things up. Since minimum distance is at least as much as a difference in length of both strings, there&#8217;s no point in calculating it when difference already exceeds a limit we chose.</p>
<p>The other trick took into an account that Levenshtein&#8217;s algorithm of two strings of comparable length has complexity of O(n2) and that my blog titles are form quite sparse space. If strings are longer than a certain limit (I arbitrarily chose 10 letters), then first calculate edit distance on a small sparse substring and then calculate the real distance only if first one was close enough.</p>
<p>When I made 1000 iterations of randomly chosen title using only first test, I got following results:</p>
<p style="text-indent:20pt;">0.003s, 0.284s, 0.167s (min, max, avg)</p>
<p>However, if I used both checks, the same 1000 iteration test got me:</p>
<p style="text-indent:20pt;">0.003s, 0.162s, 0.027s (min, max, avg)</p>
<p>So, <a href="http://markos.gaivo.net/examples/distance/distance.py" title="Extended distance functions">two simple checks</a> can speed up search up to 350 times. Not bad, but I&#8217;m not happy. This is certainly fast enough for a personal website or sites where site structure effectively divides searching to relatively small sets of possible hits, but there are plenty of sites where it would be too slow.</p>
<p>I tried to simplify searching using distance to map strings to coordinate system, which was at least hopelessly naive if not downright dumb. A much better approach would be to read more, which is what I&#8217;m doing now.</p>
<p>By the way, I&#8217;ve also tried to speed it up using Pyrex, but got pretty much same results, which means I either don&#8217;t know how to use Pyrex or Python optimizes well. Or both.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2006-11-10T02:17:48+00:00">November 10, 2006</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=211#comments" title="Comment on Speeding up Levenshtein">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=210" rel="bookmark">Handling 404</a></h1>

			<div class="post-text">
				<p>This blog doesn&#8217;t use descriptive URLs, which is not the only time I screwed this up for no good reason. In this case it was mainly laziness and smug i-don&#8217;t-care-if-people-find-me attitude, but I hadn&#8217;t really realized how stupid this decision was until I started thinking about the problem of missing pages (error 404).</p>
<p>It always bugged me how useless most 404 pages are. Sure, I could notify the webmaster about a broken link, but that won&#8217;t help me find what I&#8217;m looking for. Can&#8217;t we do better than that?</p>
<p>As it happens we often can.  There&#8217;s an unlimited number of ways in which visitors can fail to reach their destination, but majority of them probably fall in four categories:</p>
<ul>
<li>content moved elsewhere</li>
<li>broken links</li>
<li>typos</li>
<li>bad memory recall</li>
</ul>
<p><strong>Content moved elsewhere</strong></p>
<p>Many believe that pages should be permanent and links shouldn&#8217;t break over time. Yet sometimes we either have little control over this or there are good reasons for breakage. We should still try to mitigate such situation by guiding visitors to correct new location when possible.</p>
<p>This is done with HTTP redirects. If content was moved only temporary, then response should have a status code of 302 and contain a link in the header to correct current address. If move was permanent, then the same thing is achieved with code 301.</p>
<p>Missing pages amount to around 0.6% of hits on this website. They would be around 8% if redirects weren&#8217;t used.</p>
<p><strong>Broken links</strong></p>
<p>Broken links appear when email clients break URL longer than maximum line length or from botched copy operation. This usually means that address is cut off and part we have is incomplete, but otherwise correct. Handling such links can range from trivial to impossible. Let&#8217;s look at one Wikipedia link as an example:</p>
<p style="text-indent:20pt;"><a href="http://en.wikipedia.org/wiki/Longest_common_subsequence_problem" title="Link to article about longest common sequence problem">http://en.wikipedia.org/wiki/Longest_common_subsequence_problem</a></p>
<p>Let&#8217;s say that link was broken near the end of it and there was <em>lem</em> missing in <em>problem</em>. Resulting address might not be complete, but there probably aren&#8217;t that many Wikipedia articles where such string forms first part of their address and it would be reasonable to assume that Wikipedia could find the right article. Alas it doesn&#8217;t.</p>
<p>On the other side of the spectrum are impossible or almost impossible guesses. If address was broken anywhere before <em>Longest</em>, then we could learn nothing from it about visitors expectations. This would look like a good place to give up.</p>
<p>However, if we are lucky, then our visitors came from one of popular search engines, which means their referrer attribute includes search string that led to our page. We can extract those keywords, use them and hopefully find that page or failing that offer a list of related pages. Not perfect, but beats plain &#8220;Not here&#8221; sign.</p>
<p><strong>Typos</p>
<p></strong>Typos are what happens when people use keyboards. I can&#8217;t live without one, but I still recognize that my fingers and my brain are not always of the same mind about how to spell a word. Letters get added, dropped or just switch places, all being a problem for a program that usually looks for that one perfect match.</p>
<p>There&#8217;s help. Edit distance algorithms, like <a href="http://en.wikipedia.org/wiki/Levenshtein_distance" title="Description of Levenshteins algorithm">Levenshtein&#8217;s</a>, can be used to measure how similar two strings really are. Matching then becomes finding the page with shortest distance from a list of its closest neighbors.</p>
<p>Downside is that algorithm is fairly computationally expensive and it might take time to find a match. I&#8217;ll explore this problem in tomorrows article.</p>
<p><strong>Bad memory requests</strong></p>
<p>The main purpose of descriptive URLs is the same as catchy domain names. Make it easy to remember address for later use, when bookmarks or browsers autocomplete can&#8217;t be used.</p>
<p>But memory is notoriously unreliable and it doesn&#8217;t work any better with web addresses. So addresses used may vary enough from the right one that they don&#8217;t get caught with edit distance algorithms. As an example, someone might try to access aforementioned Wikipedia&#8217;s article with:</p>
<p style="text-indent:20pt;">http://en.wikipedia.org/wiki/Longest_subsequence_problem</p>
<p>Calculated distance between this address and the real one is 7, which is probably more than would be real limit for matching. We can still look at referrer for clues, but we can also use requested address. In our case, we can extract keywords <em>longest</em>, <em>subsequence</em> and <em>problem</em> and use them to search for possible hits. Wikipedia doesn&#8217;t do this either, but neither do I, so I shouldn&#8217;t complain.<br />
<strong>Time to wrap it up</strong></p>
<p>I believe this approaches make a good case for logical and descriptive addresses, since most of them don&#8217;t work (well) otherwise. If someone requests an article with a nonexistent ID 145, it&#8217;s impossible to resolve which of existing ones with IDs 155, 245 or 149 he really wanted.</p>
<p>Still, sometimes descriptive addresses are not an option. I&#8217;d love to hear ideas or practical experience of how to handle such cases.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2006-11-08T12:31:43+00:00">November 8, 2006</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=210#comments" title="Comment on Handling 404">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=207" rel="bookmark">HyperScope and my blog&#8217;s evolution</a></h1>

			<div class="post-text">
				<p>I&#8217;ve been writing less lately, which had little to do with summer laziness and more with me thinking about publishing on the web.</p>
<p>Many have said that Internet (or Web) is not a television, but neither is it a magazine or a book. Yet I find myself again and again leaning on preconceptions picked up from my favorite medium. So this summer has been spent exploring my preconceived notions and trying to find out which of them still make sense on the web and how to tackle those which don&#8217;t.</p>
<p>And the result of this exploration? I still don&#8217;t like WordPress, so I might go about writing my own publishing platform which would offer me an opportunity to test some of newfound ideas. Or I won&#8217;t, recognizing vast amount of time needed and I&#8217;ll end up only writing an article or two. But what I&#8217;m certain I will do is write less.</p>
<p>In a world where every monkey can publish so almost every one of us eventually does restraint is a virtue. There were too many posts that neither benefited me nor those who came across them. Maybe I won&#8217;t change the signal-noise ratio, but I will put less crap out there in absolute terms.</p>
<p>Related to all these thinking is a recent announcement of <a href="http://hyperscope.org/">HyperScope</a>. Doug Engelbart&#8217;s vision of <a href="http://hyperscope.org/hyperscope/src/demos/augment-132082.opml">Open Hyperdocument System</a> (link may not work in every browser) has been a source of many ideas this summer and it&#8217;s certainly nice to finally have available a system to test at least some of them.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2006-09-07T14:07:37+00:00">September 7, 2006</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=207#comments" title="Comment on HyperScope and my blog&#8217;s evolution">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
		
		<nav class="pagination">
			<ul>
				<li><a href="http://markos.gaivo.net/blog/?cat=5&#038;paged=10" >&laquo; Newer articles</a></li>
				<li><a href="http://markos.gaivo.net/blog/?cat=5&#038;paged=12" >Older articles &raquo;</a></li>
			</ul>
		</nav>
	</section>


	<footer>
		<ul>
			<li>&copy; 2005-2015 Marko Samastur</li>
			
			<li><a href="http://markos.gaivo.net/blog/?feed=rss2">Entries feed</a></li>
			<li><a href="http://markos.gaivo.net/blog/?feed=comments-rss2">Comments feed</a></li>
		</ul>
		<a href="/"><img src="/img/markos_light_small_bg.png" alt="logo" class="mini-logo" /></a>
	</footer>
	<script src="/js/jquery.js"></script>
	<script src="/js/all.js"></script>
	<!--script src="/mint/?js" type="text/javascript"></script-->

	<!-- Google analytics -->
	<script type="text/javascript">

	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-152438-1']);
	  _gaq.push(['_trackPageview']);
	</script>
	<script src="/js/cookie.js"></script>
</body>
</html>
