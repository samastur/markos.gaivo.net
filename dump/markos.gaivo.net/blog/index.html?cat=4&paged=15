<!DOCTYPE html>
<html lang="en">
<head>
	<title>A notch above a monkey &raquo; Web</title>
	<meta charset="utf-8" />
	
	<meta name="viewport" content="width=device-width, initial-scale=1.0" /> 

	<link rel="shortcut icon" href="/img/markos.ico" />
	
	<meta name="generator" content="WordPress 3.0.5" /> <!-- leave this for stats please -->

	<link href="http://fast.fonts.com/cssapi/aee9b60b-8e94-47f8-b586-3ecbfab51d1c.css" rel="stylesheet" type="text/css" />
	<link rel="stylesheet" type="text/css" href="css/home.css" media="screen" title="Light theme" />
	<link rel="alternate stylesheet" type="text/css" href="css/home_dark.css" media="screen" title="Dark theme" />
	<link rel="stylesheet" href="css/ipad.css" media="only screen and (min-device-width : 768px) and (max-device-width : 1024px)">
	<link rel="stylesheet" type="text/css" href="css/smallscreen.css" media="only screen and (max-width: 700px)" />

	<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://markos.gaivo.net/blog/?feed=rss2" />
	<link rel="alternate" type="application/atom+xml" title="Atom 1.0" href="http://markos.gaivo.net/blog/?feed=atom" />
	<link rel='canonical' href='http://markos.gaivo.net/blog/?p=664' />

	<link rel="pingback" href="http://markos.gaivo.net/blog/xmlrpc.php" />

	<link rel="alternate" type="application/rss+xml" title="A notch above a monkey &raquo; Web Category Feed" href="http://markos.gaivo.net/blog/?feed=rss2&amp;cat=4" />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://markos.gaivo.net/blog/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://markos.gaivo.net/blog/wp-includes/wlwmanifest.xml" /> 
<link rel='index' title='A notch above a monkey' href='http://markos.gaivo.net/blog' />
<meta name="generator" content="WordPress 3.0.5" />

	<!--[if lt IE 9]>
	<script src="/js/html5.js"></script>
	<![endif]-->
</head>
<body>
	<section class="envelope posts">
		<header>
			<h1><a href="http://markos.gaivo.net/blog/">A notch above a monkey</a></h1>
		</header>
		<nav class="colophon">
			<h1>By Marko Samastur</h1>
			<ul>
				<li><a href="/">About me</a></li>
				<li><a href="http://markos.gaivo.net/blog/?feed=atom">Subscribe</a></li>
			</ul>
		</nav>

	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=232" rel="bookmark">W3C and old web</a></h1>

			<div class="post-text">
				<p>Andy is among many feeling <a href="http://www.andybudd.com/archives/2007/06/whither_w3c/index.php">frustrated</a> with slow progress of CSS3 specifications and role W3C plays or should play in their birth. Having no part in any standardization process with corresponding amount of experience in developing a specification, I&#8217;m certainly ill qualified for comment on it with any reasonable amount of certainty.</p>
<p>I am, for better or worse, a blogger and I was at WWW2007, so I do have an opinion that like any true blogger find irresistible not to share even if it is in all likelihood wrong. In short, I believe the current state is a result of fairly insignificant intersection between people feeling the pain and those able to do much about it.</p>
<p>At first we wanted to present information and nineties were largely spent developing tools to do so in efficient enough manner. Partial browser stagnation, Mozilla development and CSS2 together with HTML4/XHTML1 more or less brought it far enough that we started having bigger dreams, wanting to do new stuff with our data. Just displaying it on a page doesn&#8217;t feel enough anymore.</p>
<p>These days there is a lot of talk about semantic web, which doesn&#8217;t mean same to all people, but is mostly understood as adding meaning to published outputs in ways friendlier to later manipulation and hence more useful. Tools ranging from feeds and microformats to SPARQL might be different, but most are marching in same direction.</p>
<p>This doesn&#8217;t mean that current set of standards are perfect, but they are good enough that most of W3C doesn&#8217;t see them as a still open problem and has moved on to work on other more important things. You can probably listen to Tim Berners-Lee for hours these days without him muttering words HTML or CSS. They are also good enough for general public, which doesn&#8217;t care much about how something is done as long as it appears to work, to get what it wants.</p>
<p>There are approximately as many Pandas in world as developers with a sense of esthetics, so it is hardly surprising that people bothered enough with current state to complain are mainly designers who care about doing things right. Sadly they are not usually well represented in standards bodies and as mentioned there isn&#8217;t an outside pressure that could compensate.</p>
<p>The only hope I see for new push comes from browser makers who probably don&#8217;t want be relegated to a part of an easily replaceable platform for running Flash/Silverlight/Whathaveyou plugins. Hopefully money flowing to them from search engines is good enough to finance a greater effort than one done so far.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2007-06-18T13:06:30+00:00">June 18, 2007</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=232#comments" title="Comment on W3C and old web">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=227" rel="bookmark">Google Gears Goodies</a></h1>

			<div class="post-text">
				<p>It&#8217;s an expected fact of a geek life that interesting technologies and gadgets appear when you don&#8217;t have either means or time to play with them. No surprise then that <a href="http://code.google.com/apis/gears/index.html">Google Gears</a> was announced exactly at such a time for me. As you&#8217;ve probably read elsewhere, Google Gears is a browser extension for Firefox and Internet Explorer (with Safari coming up) which lets developers create web applications that can also run offline on Windows, Mac OS X and Linux.</p>
<p>Google isn&#8217;t the first company doing something like this. Adobe has Apollo, Microsoft is working on its own thing, Mozilla added support for offline storage in version 2 of the fox and there are some less well known attempts like Dojo&#8217;s. What makes it special are few things.</p>
<p>First, unlike Apollo or Firefox, it&#8217;s not a special environment and it&#8217;s as cross-browser and cross-platform as it gets these days. Google is also trying to build an industry support for this and Adobe already <a href="http://shebanation.com/2007/05/30/google-gears/">announced</a> it will support Gears API in Apollo. Same has <a href="http://ajaxian.com/archives/audible-ajax-episode-21-dojo-offline-on-google-gears">already been done</a> by Dojo Toolkit. There&#8217;s also <a href="http://erik.eae.net/archives/2007/05/30/19.06.10/#comments">an intention</a> to make it an open standard by submitting proposal to WHATWG/W3C (and hopefully them accepting it).</p>
<p>Personally, I can&#8217;t wait to play with WorkerPool API (which seems to be overlooked in all the excitement). Having a possibility of running time-intensive operations in a background without the fear of triggering &#8220;unresponsive script&#8221; dialog is a wish come true. Even though you can&#8217;t access objects <em>document</em> and <em>window</em> (and hence any part of the DOM). Reason for this is that background scripts don&#8217;t share any execution state and hence can&#8217;t all access unique objects like aforementioned ones.</p>
<p>This might limit usefulness of the API somewhat, but there are still plenty of uses that come to my mind. What also comes to my mind is a problem, that isn&#8217;t really technological. Web applications gave impression to public of being fairly safe to use even on public computers (which isn&#8217;t really true) and I fear many won&#8217;t understand that new tools may now store private data where they don&#8217;t expect or want them to.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2007-05-31T15:00:32+00:00">May 31, 2007</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=227#comments" title="Comment on Google Gears Goodies">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
	
		<article>
			<h1 class="storytitle"><a href="http://markos.gaivo.net/blog/?p=225" rel="bookmark">WWW2007</a></h1>

			<div class="post-text">
				<p><a href="http://www2007.org/">WWW2007</a> is wrapping up tomorrow, but today is the last day I am attending. It&#8217;s been really refreshing to be at a web oriented gathering without hearing anybody say: &#8220;Web 2.0&#8243;.</p>
<p>I enjoyed listening to talks and learned that I have to brush up my math and maybe learn a new thing or two. I still learned a lot despite my personal shortcomings.</p>
<p>My original reason for attending was <a href="http://airweb.cse.lehigh.edu/2007/">AIRWeb07</a>, a workshop on adversarial information retrieval on web, because I wanted to learn what anti-spam community is working on and what sort of ideas and tools are being discussed.</p>
<p>The answer to an outsider like me seems mainly to be a problem of web spam polluting search engines and algorithms trying to discover spam pages from graphs of connected pages.</p>
<p>It is a very simplified description, probably even too simplified, and I have to say that I admire the work and ideas done and shown at the conference. At the same time I was very surprised that focus has been so much on links and practically none on characteristics of spam pages themselves (with notable exception of a submission by <a href="http://plg.uwaterloo.ca/~gvcormac/">Gordon Cormack</a>). I understand that crawlers are somewhat out of vogue in research community, but it still seemed kind of odd.</p>
<p>It is as if someone trying to know me would completely ignore what I say and solely concentrate on who am I hanging out with and how do I go about it. It seemed to me that the best way would be to combine both, which is what prof. Cormack proposed as well.</p>
<p>In a way I think I may understand this focus. It&#8217;s very easy to add spam links on an open participatory web and obviously nobody can control what gets published on all those pages out there. So it&#8217;s natural for search companies to concentrate on points that they do control, like their index.</p>
<p>Still, I feel as if not enough has been done on preventing stuff like comment spam. Better tools would only lead to more isolated spam pages and therefore to an easier extraction of spam networks from an index.</p>
<p>Then again, I don&#8217;t do this kind of research for a living and may be only talking nonsense.</p>
<p>The other thing that&#8217;s been on my mind is a general agreement that this is an arms race and one which won&#8217;t be won unless financial incentives driving spammers can be eliminated. Question came up if we should try to break our own protections (as cryptographers do) and how would we fare?</p>
<p>I have no doubt that people I met fighting spam are much smarter than most of their opponents, which is why I don&#8217;t doubt that they could do it. I doubt only if they should do it.</p>
<p>It&#8217;s not really intuitive that the best thing in an arms race would be to show the other side how to build a nuke. Especially when it seems we are busy enough fighting problem in its current variations. Then again, I&#8217;m not convinced it&#8217;s a bad idea either.</p>
<p>I won&#8217;t go much into other talks, as I feel even less qualified to judge and anyone can get a better insight just by reading accepted papers that are all available online. What I heard or read has been in general of a high quality and if this year is anything to go by, then try to attend next one, which will be next April in Beijing.</p>
<p>By the way, visiting Banff is a must even without a conference as an excuse, since the place and even more its surroundings are just stunning. And if you do decide to go, do yourself a favor and contact <a href="http://www.tarry.ca/">Alicyn</a> for a place to stay.</p>
			</div>

			<footer class="post-metadata">
				<ul>
					<li>Published on <time datetime="2007-05-11T18:17:03+00:00">May 11, 2007</time></li>
					<li><a href="http://markos.gaivo.net/blog/?p=225#comments" title="Comment on WWW2007">Add your comment</a> </li>
				</ul>
			</footer>
		</article>
		
		<nav class="pagination">
			<ul>
				<li><a href="http://markos.gaivo.net/blog/?cat=4&#038;paged=14" >&laquo; Newer articles</a></li>
				<li><a href="http://markos.gaivo.net/blog/?cat=4&#038;paged=16" >Older articles &raquo;</a></li>
			</ul>
		</nav>
	</section>


	<footer>
		<ul>
			<li>&copy; 2005-2015 Marko Samastur</li>
			
			<li><a href="http://markos.gaivo.net/blog/?feed=rss2">Entries feed</a></li>
			<li><a href="http://markos.gaivo.net/blog/?feed=comments-rss2">Comments feed</a></li>
		</ul>
		<a href="/"><img src="/img/markos_light_small_bg.png" alt="logo" class="mini-logo" /></a>
	</footer>
	<script src="/js/jquery.js"></script>
	<script src="/js/all.js"></script>
	<!--script src="/mint/?js" type="text/javascript"></script-->

	<!-- Google analytics -->
	<script type="text/javascript">

	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-152438-1']);
	  _gaq.push(['_trackPageview']);
	</script>
	<script src="/js/cookie.js"></script>
</body>
</html>
